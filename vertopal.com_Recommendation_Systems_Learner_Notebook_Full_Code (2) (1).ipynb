{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project: Amazon Product Recommendation System**<a href=\"#Project:-Amazon-Product-Recommendation-System\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "# **Marks: 40**<a href=\"#Marks:-40\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Welcome to the project on Recommendation Systems. We will work with the\n",
    "Amazon product reviews dataset for this project. The dataset contains\n",
    "ratings of different electronic products. It does not include\n",
    "information about the products or reviews to avoid bias while building\n",
    "the model.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Context:**<a href=\"#Context:\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Today, information is growing exponentially with volume, velocity and\n",
    "variety throughout the globe. This has lead to information overload, and\n",
    "too many choices for the consumer of any business. It represents a real\n",
    "dilemma for these consumers and they often turn to denial. Recommender\n",
    "Systems are one of the best tools that help recommending products to\n",
    "consumers while they are browsing online. Providing personalized\n",
    "recommendations which is most relevant for the user is what's most\n",
    "likely to keep them engaged and help business.\n",
    "\n",
    "E-commerce websites like Amazon, Walmart, Target and Etsy use different\n",
    "recommendation models to provide personalized suggestions to different\n",
    "users. These companies spend millions of dollars to come up with\n",
    "algorithmic techniques that can provide personalized recommendations to\n",
    "their users.\n",
    "\n",
    "Amazon, for example, is well-known for its accurate selection of\n",
    "recommendations in its online site. Amazon's recommendation system is\n",
    "capable of intelligently analyzing and predicting customers' shopping\n",
    "preferences in order to offer them a list of recommended products.\n",
    "Amazon's recommendation algorithm is therefore a key element in using AI\n",
    "to improve the personalization of its website. For example, one of the\n",
    "baseline recommendation models that Amazon uses is item-to-item\n",
    "collaborative filtering, which scales to massive data sets and produces\n",
    "high-quality recommendations in real-time.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Objective:**<a href=\"#Objective:\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "You are a Data Science Manager at Amazon, and have been given the task\n",
    "of building a recommendation system to recommend products to customers\n",
    "based on their previous ratings for other products. You have a\n",
    "collection of labeled data of Amazon reviews of products. The goal is to\n",
    "extract meaningful insights from the data and build a recommendation\n",
    "system that helps in recommending products to online consumers.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Dataset:**<a href=\"#Dataset:\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "The Amazon dataset contains the following attributes:\n",
    "\n",
    "-   **userId:** Every user identified with a unique id\n",
    "-   **productId:** Every product identified with a unique id\n",
    "-   **Rating:** The rating of the corresponding product by the\n",
    "    corresponding user\n",
    "-   **timestamp:** Time of the rating. We **will not use this column**\n",
    "    to solve the current problem\n",
    "\n",
    "**Note:** The code has some user defined functions that will be usefull\n",
    "while making recommendations and measure model performance, you can use\n",
    "these functions or can create your own functions.\n",
    "\n",
    "Sometimes, the installation of the surprise library, which is used to\n",
    "build recommendation systems, faces issues in Jupyter. To avoid any\n",
    "issues, it is advised to use **Google Colab** for this project.\n",
    "\n",
    "Let's start by mounting the Google drive on Colab.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "**Installing surprise library**\n",
    "\n",
    "In \\[1\\]:\n",
    "\n",
    "    !pip install surprise\n",
    "\n",
    "    Collecting surprise\n",
    "      Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
    "    Collecting scikit-surprise (from surprise)\n",
    "      Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
    "         ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 154.4/154.4 kB 1.7 MB/s eta 0:00:00\n",
    "      Installing build dependencies ... done\n",
    "      Getting requirements to build wheel ... done\n",
    "      Preparing metadata (pyproject.toml) ... done\n",
    "    Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
    "    Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.26.4)\n",
    "    Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.13.1)\n",
    "    Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
    "    Building wheels for collected packages: scikit-surprise\n",
    "      Building wheel for scikit-surprise (pyproject.toml) ... done\n",
    "      Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357270 sha256=19456ba278206ffe8c11ffe87b289e2874c05246ec3529bd57a0114015c43603\n",
    "      Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
    "    Successfully built scikit-surprise\n",
    "    Installing collected packages: scikit-surprise, surprise\n",
    "    Successfully installed scikit-surprise-1.1.4 surprise-0.1\n",
    "\n",
    "## **Importing the necessary libraries and overview of the dataset**<a href=\"#Importing-the-necessary-libraries-and-overview-of-the-dataset\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[3\\]:\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    from collections import defaultdict\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "### **Loading the data**<a href=\"#Loading-the-data\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "-   Import the Dataset\n",
    "-   Add column names \\['user_id', 'prod_id', 'rating', 'timestamp'\\]\n",
    "-   Drop the column timestamp\n",
    "-   Copy the data to another DataFrame called **df**\n",
    "\n",
    "In \\[15\\]:\n",
    "\n",
    "    data = pd.read_csv('ratings_Electronics.csv')\n",
    "    data.iloc[-1] = data.columns\n",
    "    data.index = data.index + 1\n",
    "    data = data.sort_index()\n",
    "    data.columns = ['user_id', 'prod_id', 'rating', 'timestamp']\n",
    "    data = data.drop('timestamp', axis = 1)\n",
    "    df = data.copy()\n",
    "    df\n",
    "\n",
    "    <ipython-input-15-911b8f313f8b>:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '5.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
    "      data.iloc[-1] = data.columns\n",
    "    <ipython-input-15-911b8f313f8b>:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1365811200' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
    "      data.iloc[-1] = data.columns\n",
    "\n",
    "Out\\[15\\]:\n",
    "\n",
    "|         | user_id        | prod_id    | rating |\n",
    "|---------|----------------|------------|--------|\n",
    "| 1       | A2CX7LUOHB2NDG | 0321732944 | 5.0    |\n",
    "| 2       | A2NWSAGRHCP8N5 | 0439886341 | 1.0    |\n",
    "| 3       | A2WNBOD3WNDNKT | 0439886341 | 3.0    |\n",
    "| 4       | A1GI0U4ZRJA8WN | 0439886341 | 1.0    |\n",
    "| 5       | A1QGNMC6O1VW39 | 0511189877 | 5.0    |\n",
    "| ...     | ...            | ...        | ...    |\n",
    "| 7824477 | A2YZI3C9MOHC0L | BT008UKTMW | 5.0    |\n",
    "| 7824478 | A322MDK0M89RHN | BT008UKTMW | 5.0    |\n",
    "| 7824479 | A1MH90R0ADMIK0 | BT008UKTMW | 4.0    |\n",
    "| 7824480 | A10M2KEFPEQDHN | BT008UKTMW | 4.0    |\n",
    "| 7824481 | AKM1MP6P0OYPR  | 0132793040 | 5.0    |\n",
    "\n",
    "7824481 rows × 3 columns\n",
    "\n",
    "![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld2JveD0iMCAtOTYwIDk2MCA5NjAiPgogICAgPHBhdGggZD0iTTEyMC0xMjB2LTcyMGg3MjB2NzIwSDEyMFptNjAtNTAwaDYwMHYtMTYwSDE4MHYxNjBabTIyMCAyMjBoMTYwdi0xNjBINDAwdjE2MFptMCAyMjBoMTYwdi0xNjBINDAwdjE2MFpNMTgwLTQwMGgxNjB2LTE2MEgxODB2MTYwWm00NDAgMGgxNjB2LTE2MEg2MjB2MTYwWk0xODAtMTgwaDE2MHYtMTYwSDE4MHYxNjBabTQ0MCAwaDE2MHYtMTYwSDYyMHYxNjBaIj48L3BhdGg+CiAgPC9zdmc+)\n",
    "\n",
    "![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld2JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCI+CiAgICA8Zz4KICAgICAgICA8cGF0aCBkPSJNMTkgM0g1Yy0xLjEgMC0yIC45LTIgMnYxNGMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjVjMC0xLjEtLjktMi0yLTJ6TTkgMTdIN3YtN2gydjd6bTQgMGgtMlY3aDJ2MTB6bTQgMGgtMnYtNGgydjR6Ij48L3BhdGg+CiAgICA8L2c+Cjwvc3ZnPg==)\n",
    "\n",
    "![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld2JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCI+CiAgICA8cGF0aCBkPSJNNywxOUg4LjRMMTguNDUsOSwxNyw3LjU1LDcsMTcuNlpNNSwyMVYxNi43NUwxOC40NSwzLjMyYTIsMiwwLDAsMSwyLjgzLDBsMS40LDEuNDNhMS45MSwxLjkxLDAsMCwxLC41OCwxLjQsMS45MSwxLjkxLDAsMCwxLS41OCwxLjRMOS4yNSwyMVpNMTguNDUsOSwxNyw3LjU1Wm0tMTIsM0E1LjMxLDUuMzEsMCwwLDAsNC45LDguMSw1LjMxLDUuMzEsMCwwLDAsMSw2LjUsNS4zMSw1LjMxLDAsMCwwLDQuOSw0LjksNS4zMSw1LjMxLDAsMCwwLDYuNSwxLDUuMzEsNS4zMSwwLDAsMCw4LjEsNC45LDUuMzEsNS4zMSwwLDAsMCwxMiw2LjUsNS40Niw1LjQ2LDAsMCwwLDYuNSwxMloiPjwvcGF0aD4KICA8L3N2Zz4=)\n",
    "\n",
    "**As this dataset is very large and has 7,824,482 observations, it is\n",
    "not computationally possible to build a model using this. Moreover, many\n",
    "users have only rated a few products and also some products are rated by\n",
    "very few users. Hence, we can reduce the dataset by considering certain\n",
    "logical assumptions.**\n",
    "\n",
    "Here, we will be taking users who have given at least 50 ratings, and\n",
    "the products that have at least 5 ratings, as when we shop online we\n",
    "prefer to have some number of ratings of a product.\n",
    "\n",
    "In \\[16\\]:\n",
    "\n",
    "    # Get the column containing the users\n",
    "    users = df.user_id\n",
    "\n",
    "    # Create a dictionary from users to their number of ratings\n",
    "    ratings_count = dict()\n",
    "\n",
    "    for user in users:\n",
    "\n",
    "        # If we already have the user, just add 1 to their rating count\n",
    "        if user in ratings_count:\n",
    "            ratings_count[user] += 1\n",
    "\n",
    "        # Otherwise, set their rating count to 1\n",
    "        else:\n",
    "            ratings_count[user] = 1\n",
    "\n",
    "In \\[17\\]:\n",
    "\n",
    "    # We want our users to have at least 50 ratings to be considered\n",
    "    RATINGS_CUTOFF = 50\n",
    "\n",
    "    remove_users = []\n",
    "\n",
    "    for user, num_ratings in ratings_count.items():\n",
    "        if num_ratings < RATINGS_CUTOFF:\n",
    "            remove_users.append(user)\n",
    "\n",
    "    df = df.loc[ ~ df.user_id.isin(remove_users)]\n",
    "\n",
    "In \\[18\\]:\n",
    "\n",
    "    # Get the column containing the products\n",
    "    prods = df.prod_id\n",
    "\n",
    "    # Create a dictionary from products to their number of ratings\n",
    "    ratings_count = dict()\n",
    "\n",
    "    for prod in prods:\n",
    "\n",
    "        # If we already have the product, just add 1 to its rating count\n",
    "        if prod in ratings_count:\n",
    "            ratings_count[prod] += 1\n",
    "\n",
    "        # Otherwise, set their rating count to 1\n",
    "        else:\n",
    "            ratings_count[prod] = 1\n",
    "\n",
    "In \\[19\\]:\n",
    "\n",
    "    # We want our item to have at least 5 ratings to be considered\n",
    "    RATINGS_CUTOFF = 5\n",
    "\n",
    "    remove_users = []\n",
    "\n",
    "    for user, num_ratings in ratings_count.items():\n",
    "        if num_ratings < RATINGS_CUTOFF:\n",
    "            remove_users.append(user)\n",
    "\n",
    "    df_final = df.loc[~ df.prod_id.isin(remove_users)]\n",
    "\n",
    "In \\[20\\]:\n",
    "\n",
    "    # Print a few rows of the imported dataset\n",
    "    df_final.head()\n",
    "\n",
    "Out\\[20\\]:\n",
    "\n",
    "|      | user_id        | prod_id    | rating |\n",
    "|------|----------------|------------|--------|\n",
    "| 1310 | A3LDPF5FMB782Z | 1400501466 | 5.0    |\n",
    "| 1322 | A1A5KUIIIHFF4U | 1400501466 | 1.0    |\n",
    "| 1335 | A2XIOXRRYX0KZY | 1400501466 | 3.0    |\n",
    "| 1451 | AW3LX47IHPFRL  | 1400501466 | 5.0    |\n",
    "| 1456 | A1E3OB6QMBKRYZ | 1400501466 | 1.0    |\n",
    "\n",
    "![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld2JveD0iMCAtOTYwIDk2MCA5NjAiPgogICAgPHBhdGggZD0iTTEyMC0xMjB2LTcyMGg3MjB2NzIwSDEyMFptNjAtNTAwaDYwMHYtMTYwSDE4MHYxNjBabTIyMCAyMjBoMTYwdi0xNjBINDAwdjE2MFptMCAyMjBoMTYwdi0xNjBINDAwdjE2MFpNMTgwLTQwMGgxNjB2LTE2MEgxODB2MTYwWm00NDAgMGgxNjB2LTE2MEg2MjB2MTYwWk0xODAtMTgwaDE2MHYtMTYwSDE4MHYxNjBabTQ0MCAwaDE2MHYtMTYwSDYyMHYxNjBaIj48L3BhdGg+CiAgPC9zdmc+)\n",
    "\n",
    "![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld2JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCI+CiAgICA8Zz4KICAgICAgICA8cGF0aCBkPSJNMTkgM0g1Yy0xLjEgMC0yIC45LTIgMnYxNGMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjVjMC0xLjEtLjktMi0yLTJ6TTkgMTdIN3YtN2gydjd6bTQgMGgtMlY3aDJ2MTB6bTQgMGgtMnYtNGgydjR6Ij48L3BhdGg+CiAgICA8L2c+Cjwvc3ZnPg==)\n",
    "\n",
    "## **Exploratory Data Analysis**<a href=\"#Exploratory-Data-Analysis\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### **Shape of the data**<a href=\"#Shape-of-the-data\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### **Check the number of rows and columns and provide observations.**<a\n",
    "href=\"#Check-the-number-of-rows-and-columns-and-provide-observations.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[21\\]:\n",
    "\n",
    "    # Check the number of rows and columns and provide observations\n",
    "    print(df_final.shape[0], df_final.shape[1])\n",
    "\n",
    "    65290 3\n",
    "\n",
    "Our data has 65290 rows and 3 columns\n",
    "\n",
    "### **Data types**<a href=\"#Data-types\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[22\\]:\n",
    "\n",
    "    # Check Data types and provide observations\n",
    "    df_final.info()\n",
    "\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    Index: 65290 entries, 1310 to 7824427\n",
    "    Data columns (total 3 columns):\n",
    "     #   Column   Non-Null Count  Dtype \n",
    "    ---  ------   --------------  ----- \n",
    "     0   user_id  65290 non-null  object\n",
    "     1   prod_id  65290 non-null  object\n",
    "     2   rating   65290 non-null  object\n",
    "    dtypes: object(3)\n",
    "    memory usage: 4.0+ MB\n",
    "\n",
    "All of our data is of dtype object\n",
    "\n",
    "### **Checking for missing values**<a href=\"#Checking-for-missing-values\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[23\\]:\n",
    "\n",
    "    # Check for missing values present and provide observations\n",
    "    df_final.isna().sum()\n",
    "\n",
    "Out\\[23\\]:\n",
    "\n",
    "|         | 0   |\n",
    "|---------|-----|\n",
    "| user_id | 0   |\n",
    "| prod_id | 0   |\n",
    "| rating  | 0   |\n",
    "\n",
    "  \n",
    "**dtype:** int64\n",
    "\n",
    "We have no null values, so we have a complete dataset\n",
    "\n",
    "### **Summary Statistics**<a href=\"#Summary-Statistics\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[35\\]:\n",
    "\n",
    "    # Summary statistics of 'rating' variable and provide observations\n",
    "\n",
    "    df_final['rating'].astype('float64')\n",
    "    df_final['rating'].describe(include=[float])\n",
    "    print(df_final['rating'].mean())\n",
    "    print(df_final['rating'].median())\n",
    "\n",
    "    4.294807780670853\n",
    "    5.0\n",
    "\n",
    "The rating variable has a mean of 4.29 and a median of 5, meaning that\n",
    "most cusotmers rate the products highly\n",
    "\n",
    "### **Checking the rating distribution**<a href=\"#Checking-the-rating-distribution\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[38\\]:\n",
    "\n",
    "    # Create the bar plot and provide observations\n",
    "    sns.countplot(data = df_final, x = df_final['rating'])\n",
    "\n",
    "Out\\[38\\]:\n",
    "\n",
    "    <Axes: xlabel='rating', ylabel='count'>\n",
    "\n",
    "![](data:image/png;base64,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%0A)\n",
    "\n",
    "The data is skewed left which means that most of our data is on the\n",
    "right. This means that a majority of customers are satisfied with the\n",
    "products\n",
    "\n",
    "### **Checking the number of unique users and items in the dataset**<a href=\"#Checking-the-number-of-unique-users-and-items-in-the-dataset\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[53\\]:\n",
    "\n",
    "    # Number of total rows in the data and number of unique user id and product id in the data\n",
    "    print(df_final['user_id'].value_counts())\n",
    "    print(df_final['prod_id'].value_counts())\n",
    "\n",
    "    user_id\n",
    "    ADLVFFE4VBT8      295\n",
    "    A3OXHLG6DIBRW8    230\n",
    "    A1ODOGXEYECQQ8    217\n",
    "    A36K2N527TXXJN    212\n",
    "    A25C2M3QF9G7OQ    203\n",
    "                     ... \n",
    "    A16CVJUQOB6GIB      2\n",
    "    A2BGZ52M908MJY      2\n",
    "    A3DL29NLZ7SXXG      1\n",
    "    AP2NZAALUQKF5       1\n",
    "    A3MV1KKHX51FYT      1\n",
    "    Name: count, Length: 1540, dtype: int64\n",
    "    prod_id\n",
    "    B0088CJT4U    206\n",
    "    B003ES5ZUU    184\n",
    "    B000N99BBC    167\n",
    "    B007WTAJTO    164\n",
    "    B00829TIEK    149\n",
    "                 ... \n",
    "    B00368CDH6      5\n",
    "    B0036AZA6A      5\n",
    "    B0036E8V08      5\n",
    "    B0036QL1JY      5\n",
    "    B00LGQ6HL8      5\n",
    "    Name: count, Length: 5689, dtype: int64\n",
    "\n",
    "There are 1540 unique user id's and there are 5689 unqiue product id's\n",
    "\n",
    "### **Users with the most number of ratings**<a href=\"#Users-with-the-most-number-of-ratings\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[57\\]:\n",
    "\n",
    "    # Top 10 users based on the number of ratings\n",
    "    df_final['user_id'].value_counts().head(10)\n",
    "\n",
    "Out\\[57\\]:\n",
    "\n",
    "|                | count |\n",
    "|----------------|-------|\n",
    "| user_id        |       |\n",
    "| ADLVFFE4VBT8   | 295   |\n",
    "| A3OXHLG6DIBRW8 | 230   |\n",
    "| A1ODOGXEYECQQ8 | 217   |\n",
    "| A36K2N527TXXJN | 212   |\n",
    "| A25C2M3QF9G7OQ | 203   |\n",
    "| A680RUE1FDO8B  | 196   |\n",
    "| A1UQBFCERIP7VJ | 193   |\n",
    "| A22CW0ZHY3NJH8 | 193   |\n",
    "| AWPODHOB4GFWL  | 184   |\n",
    "| AGVWTYW0ULXHT  | 179   |\n",
    "\n",
    "  \n",
    "**dtype:** int64\n",
    "\n",
    "THe user with the most number of ratings is 'ADLVFFE4VBT8' with 295\n",
    "ratings\n",
    "\n",
    "**Now that we have explored and prepared the data, let's build the first\n",
    "recommendation system.**\n",
    "\n",
    "## **Model 1: Rank Based Recommendation System**<a href=\"#Model-1:-Rank-Based-Recommendation-System\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[69\\]:\n",
    "\n",
    "    # Calculate the average rating for each product\n",
    "    average_rating = df_final.groupby('prod_id')['rating'].mean()\n",
    "\n",
    "    # Calculate the count of ratings for each product\n",
    "    rating_count_per_product = df_final.groupby('prod_id')['rating'].count()\n",
    "\n",
    "    # Create a dataframe with calculated average and count of ratings\n",
    "    df_avgcount = pd.DataFrame({'Calculated Average': average_rating, 'Count of Ratings': rating_count_per_product})\n",
    "\n",
    "    # Sort the dataframe by average of ratings in the descending order\n",
    "    df_avgcount.sort_values(by=['Calculated Average'])\n",
    "\n",
    "    # See the first five records of the \"final_rating\" dataset\n",
    "    df_avgcount.head()\n",
    "\n",
    "Out\\[69\\]:\n",
    "\n",
    "|            | Calculated Average | Count of Ratings |\n",
    "|------------|--------------------|------------------|\n",
    "| prod_id    |                    |                  |\n",
    "| 1400501466 | 3.333333           | 6                |\n",
    "| 1400532655 | 3.833333           | 6                |\n",
    "| 1400599997 | 4.0                | 5                |\n",
    "| 9983891212 | 4.875              | 8                |\n",
    "| B00000DM9W | 5.0                | 5                |\n",
    "\n",
    "![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld2JveD0iMCAtOTYwIDk2MCA5NjAiPgogICAgPHBhdGggZD0iTTEyMC0xMjB2LTcyMGg3MjB2NzIwSDEyMFptNjAtNTAwaDYwMHYtMTYwSDE4MHYxNjBabTIyMCAyMjBoMTYwdi0xNjBINDAwdjE2MFptMCAyMjBoMTYwdi0xNjBINDAwdjE2MFpNMTgwLTQwMGgxNjB2LTE2MEgxODB2MTYwWm00NDAgMGgxNjB2LTE2MEg2MjB2MTYwWk0xODAtMTgwaDE2MHYtMTYwSDE4MHYxNjBabTQ0MCAwaDE2MHYtMTYwSDYyMHYxNjBaIj48L3BhdGg+CiAgPC9zdmc+)\n",
    "\n",
    "![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld2JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCI+CiAgICA8Zz4KICAgICAgICA8cGF0aCBkPSJNMTkgM0g1Yy0xLjEgMC0yIC45LTIgMnYxNGMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjVjMC0xLjEtLjktMi0yLTJ6TTkgMTdIN3YtN2gydjd6bTQgMGgtMlY3aDJ2MTB6bTQgMGgtMnYtNGgydjR6Ij48L3BhdGg+CiAgICA8L2c+Cjwvc3ZnPg==)\n",
    "\n",
    "In \\[89\\]:\n",
    "\n",
    "    # Defining a function to get the top n products based on the highest average rating and minimum interactions\n",
    "    def top_n_products(n, df_avg_rating, min_interactions):\n",
    "      reccomendation = df_avg_rating['Count of Ratings'] >= min_interactions\n",
    "      reccomendation = reccomendation.sort_values(ascending = False)\n",
    "      return reccomendation.index[:n]\n",
    "\n",
    "    Index(['1400501466', 'B006K55662', 'B006FNCWSY', 'B006FLENJC', 'B006EWUO22'], dtype='object', name='prod_id')\n",
    "\n",
    "### **Recommending top 5 products with 50 minimum interactions based on popularity**<a\n",
    "href=\"#Recommending-top-5-products-with-50-minimum-interactions-based-on-popularity\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[90\\]:\n",
    "\n",
    "    print(top_n_products(5, df_avgcount,50))\n",
    "\n",
    "    Index(['B000JMJWV2', 'B0081FLFQE', 'B00ARB5FLQ', 'B0015DYMVO', 'B000VX6XL6'], dtype='object', name='prod_id')\n",
    "\n",
    "### **Recommending top 5 products with 100 minimum interactions based on popularity**<a\n",
    "href=\"#Recommending-top-5-products-with-100-minimum-interactions-based-on-popularity\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[91\\]:\n",
    "\n",
    "    print(top_n_products(5, df_avgcount,100))\n",
    "\n",
    "    Index(['B004T9RR6I', 'B00829THK0', 'B007WTAJTO', 'B0088CJT4U', 'B002SZEOLG'], dtype='object', name='prod_id')\n",
    "\n",
    "We have recommended the **top 5** products by using the popularity\n",
    "recommendation system. Now, let's build a recommendation system using\n",
    "**collaborative filtering.**\n",
    "\n",
    "## **Model 2: Collaborative Filtering Recommendation System**<a href=\"#Model-2:-Collaborative-Filtering-Recommendation-System\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "### **Building a baseline user-user similarity based recommendation system**<a\n",
    "href=\"#Building-a-baseline-user-user-similarity-based-recommendation-system\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "-   Below, we are building **similarity-based recommendation systems**\n",
    "    using `cosine` similarity and using **KNN to find similar users**\n",
    "    which are the nearest neighbor to the given user.\n",
    "-   We will be using a new library, called `surprise`, to build the\n",
    "    remaining models. Let's first import the necessary classes and\n",
    "    functions from this library.\n",
    "\n",
    "In \\[92\\]:\n",
    "\n",
    "    # To compute the accuracy of models\n",
    "    from surprise import accuracy\n",
    "\n",
    "    # Class is used to parse a file containing ratings, data should be in structure - user ; item ; rating\n",
    "    from surprise.reader import Reader\n",
    "\n",
    "    # Class for loading datasets\n",
    "    from surprise.dataset import Dataset\n",
    "\n",
    "    # For tuning model hyperparameters\n",
    "    from surprise.model_selection import GridSearchCV\n",
    "\n",
    "    # For splitting the rating data in train and test datasets\n",
    "    from surprise.model_selection import train_test_split\n",
    "\n",
    "    # For implementing similarity-based recommendation system\n",
    "    from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "    # For implementing matrix factorization based recommendation system\n",
    "    from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "    # for implementing K-Fold cross-validation\n",
    "    from surprise.model_selection import KFold\n",
    "\n",
    "    # For implementing clustering-based recommendation system\n",
    "    from surprise import CoClustering\n",
    "\n",
    "**Before building the recommendation systems, let's go over some basic\n",
    "terminologies we are going to use:**\n",
    "\n",
    "**Relevant item:** An item (product in this case) that is actually\n",
    "**rated higher than the threshold rating** is relevant, if the **actual\n",
    "rating is below the threshold then it is a non-relevant item**.\n",
    "\n",
    "**Recommended item:** An item that's **predicted rating is higher than\n",
    "the threshold is a recommended item**, if the **predicted rating is\n",
    "below the threshold then that product will not be recommended to the\n",
    "user**.\n",
    "\n",
    "**False Negative (FN):** It is the **frequency of relevant items that\n",
    "are not recommended to the user**. If the relevant items are not\n",
    "recommended to the user, then the user might not buy the product/item.\n",
    "This would result in the **loss of opportunity for the service\n",
    "provider**, which they would like to minimize.\n",
    "\n",
    "**False Positive (FP):** It is the **frequency of recommended items that\n",
    "are actually not relevant**. In this case, the recommendation system is\n",
    "not doing a good job of finding and recommending the relevant items to\n",
    "the user. This would result in **loss of resources for the service\n",
    "provider**, which they would also like to minimize.\n",
    "\n",
    "**Recall:** It is the **fraction of actually relevant items that are\n",
    "recommended to the user**, i.e., if out of 10 relevant products, 6 are\n",
    "recommended to the user then recall is 0.60. Higher the value of recall\n",
    "better is the model. It is one of the metrics to do the performance\n",
    "assessment of classification models.\n",
    "\n",
    "**Precision:** It is the **fraction of recommended items that are\n",
    "relevant actually**, i.e., if out of 10 recommended items, 6 are found\n",
    "relevant by the user then precision is 0.60. The higher the value of\n",
    "precision better is the model. It is one of the metrics to do the\n",
    "performance assessment of classification models.\n",
    "\n",
    "**While making a recommendation system, it becomes customary to look at\n",
    "the performance of the model. In terms of how many recommendations are\n",
    "relevant and vice-versa, below are some most used performance metrics\n",
    "used in the assessment of recommendation systems.**\n",
    "\n",
    "### **Precision@k, Recall@ k, and F1-score@k**<a href=\"#Precision@k,-Recall@-k,-and-F1-score@k\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "**Precision@k** - It is the **fraction of recommended items that are\n",
    "relevant in `top k` predictions**. The value of k is the number of\n",
    "recommendations to be provided to the user. One can choose a variable\n",
    "number of recommendations to be given to a unique user.\n",
    "\n",
    "**Recall@k** - It is the **fraction of relevant items that are\n",
    "recommended to the user in `top k` predictions**.\n",
    "\n",
    "**F1-score@k** - It is the **harmonic mean of Precision@k and\n",
    "Recall@k**. When **precision@k and recall@k both seem to be important**\n",
    "then it is useful to use this metric because it is representative of\n",
    "both of them.\n",
    "\n",
    "### **Some useful functions**<a href=\"#Some-useful-functions\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "-   Below function takes the **recommendation model** as input and gives\n",
    "    the **precision@k, recall@k, and F1-score@k** for that model.\n",
    "-   To compute **precision and recall**, **top k** predictions are taken\n",
    "    under consideration for each user.\n",
    "-   We will use the precision and recall to compute the F1-score.\n",
    "\n",
    "In \\[93\\]:\n",
    "\n",
    "    def precision_recall_at_k(model, k = 10, threshold = 3.5):\n",
    "        \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "        # First map the predictions to each user\n",
    "        user_est_true = defaultdict(list)\n",
    "\n",
    "        # Making predictions on the test data\n",
    "        predictions = model.test(testset)\n",
    "\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "            # Sort user ratings by estimated value\n",
    "            user_ratings.sort(key = lambda x: x[0], reverse = True)\n",
    "\n",
    "            # Number of relevant items\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "            # Number of recommended items in top k\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "            # Number of relevant and recommended items in top k\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                                  for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "            # Precision@K: Proportion of recommended items that are relevant\n",
    "            # When n_rec_k is 0, Precision is undefined. Therefore, we are setting Precision to 0 when n_rec_k is 0\n",
    "\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "            # Recall@K: Proportion of relevant items that are recommended\n",
    "            # When n_rel is 0, Recall is undefined. Therefore, we are setting Recall to 0 when n_rel is 0\n",
    "\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "        # Mean of all the predicted precisions are calculated.\n",
    "        precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
    "\n",
    "        # Mean of all the predicted recalls are calculated.\n",
    "        recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
    "\n",
    "        accuracy.rmse(predictions)\n",
    "\n",
    "        print('Precision: ', precision) # Command to print the overall precision\n",
    "\n",
    "        print('Recall: ', recall) # Command to print the overall recall\n",
    "\n",
    "        print('F_1 score: ', round((2*precision*recall)/(precision+recall), 3)) # Formula to compute the F-1 score\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "-   To compute **precision and recall**, a **threshold of 3.5 and k\n",
    "    value of 10 can be considered for the recommended and relevant\n",
    "    ratings**.\n",
    "-   Think about the performance metric to choose.\n",
    "\n",
    "Below we are loading the **`rating` dataset**, which is a **pandas\n",
    "DataFrame**, into a **different format called\n",
    "`surprise.dataset.DatasetAutoFolds`**, which is required by this\n",
    "library. To do this, we will be **using the classes `Reader` and\n",
    "`Dataset`.**\n",
    "\n",
    "In \\[95\\]:\n",
    "\n",
    "    # Instantiating Reader scale with expected rating scale\n",
    "    reader_scale = Reader(rating_scale = (0,5))\n",
    "    # Loading the rating dataset\n",
    "    read_data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader_scale)\n",
    "    # Splitting the data into train and test datasets\n",
    "    trainset, testset = train_test_split(read_data, test_size = 0.2, random_state = 42)\n",
    "\n",
    "Now, we are **ready to build the first baseline similarity-based\n",
    "recommendation system** using the cosine similarity.\n",
    "\n",
    "### **Building the user-user Similarity-based Recommendation System**<a href=\"#Building-the-user-user-Similarity-based-Recommendation-System\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[102\\]:\n",
    "\n",
    "    # Declaring the similarity options\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': True}\n",
    "\n",
    "    # Initialize the KNNBasic model using sim_options provided, Verbose = False, and setting random_state = 1\n",
    "    sim_user_user = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
    "\n",
    "    # Fit the model on the training data (assuming you have a variable 'trainset' from the Surprise library)\n",
    "    sim_user_user.fit(trainset)\n",
    "\n",
    "    # Let us compute precision@k, recall@k, and f_1 score using the precision_recall_at_k function defined above\n",
    "    precision, recall, f1 = precision_recall_at_k(sim_user_user, k=5,threshold = 3.5)\n",
    "\n",
    "    RMSE: 1.0012\n",
    "    Precision:  0.871\n",
    "    Recall:  0.683\n",
    "    F_1 score:  0.766\n",
    "\n",
    "    ---------------------------------------------------------------------------\n",
    "    TypeError                                 Traceback (most recent call last)\n",
    "    <ipython-input-102-a89c4e9b7101> in <cell line: 12>()\n",
    "         10 \n",
    "         11 # Let us compute precision@k, recall@k, and f_1 score using the precision_recall_at_k function defined above\n",
    "    ---> 12 precision, recall, f1 = precision_recall_at_k(sim_user_user, k=5,threshold = 3.5)\n",
    "\n",
    "    TypeError: cannot unpack non-iterable NoneType object\n",
    "\n",
    "The scores are as follows: RMSE: 1.0012 Precision: 0.871 Recall: 0.683\n",
    "F_1 score: 0.766 This shows that our model is alright, but could use\n",
    "some improvement\n",
    "\n",
    "Let's now **predict rating for a user with `userId=A3LDPF5FMB782Z` and\n",
    "`productId=1400501466`** as shown below. Here the user has already\n",
    "interacted or watched the product with productId '1400501466' and given\n",
    "a rating of 5.\n",
    "\n",
    "In \\[103\\]:\n",
    "\n",
    "    # Predicting rating for a sample user with an interacted product\n",
    "    sim_user_user.predict(\"A3LDPF5FMB782Z\", \"1400501466\", r_ui = 5, verbose = True)\n",
    "\n",
    "    user: A3LDPF5FMB782Z item: 1400501466 r_ui = 5.00   est = 3.40   {'actual_k': 5, 'was_impossible': False}\n",
    "\n",
    "Out\\[103\\]:\n",
    "\n",
    "    Prediction(uid='A3LDPF5FMB782Z', iid='1400501466', r_ui=5, est=3.4, details={'actual_k': 5, 'was_impossible': False})\n",
    "\n",
    "The prediction was pretty accurate, both estimating a r_ui of 4 and a\n",
    "est of 3.4. The model also classifies this prediction as possible\n",
    "\n",
    "Below is the **list of users who have not seen the product with product\n",
    "id \"1400501466\"**.\n",
    "\n",
    "In \\[104\\]:\n",
    "\n",
    "    # Find unique user_id where prod_id is not equal to \"1400501466\"\n",
    "    df_final[df_final.prod_id != \"1400501466\"].user_id.unique()\n",
    "\n",
    "Out\\[104\\]:\n",
    "\n",
    "    array(['A2ZR3YTMEEIIZ4', 'A3CLWR1UUZT6TG', 'A5JLAU2ARJ0BO', ...,\n",
    "           'A215WH6RUDUCMP', 'A38C12950IM24P', 'A2J4XMWKR8PPD0'], dtype=object)\n",
    "\n",
    "-   It can be observed from the above list that **user \"A34BZM6S9L7QI4\"\n",
    "    has not seen the product with productId \"1400501466\"** as this\n",
    "    userId is a part of the above list.\n",
    "\n",
    "**Below we are predicting rating for `userId=A34BZM6S9L7QI4` and\n",
    "`prod_id=1400501466`.**\n",
    "\n",
    "In \\[105\\]:\n",
    "\n",
    "    # Predicting rating for a sample user with a non interacted product\n",
    "    sim_user_user.predict(\"A34BZM6S9L7QI4\", \"1400501466\", verbose = True)\n",
    "\n",
    "    user: A34BZM6S9L7QI4 item: 1400501466 r_ui = None   est = 4.29   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
    "\n",
    "Out\\[105\\]:\n",
    "\n",
    "    Prediction(uid='A34BZM6S9L7QI4', iid='1400501466', r_ui=None, est=4.292024046561495, details={'was_impossible': True, 'reason': 'Not enough neighbors.'})\n",
    "\n",
    "The model seems to run well as a the sample user with the non interacted\n",
    "product is correctly classified as not possible.\n",
    "\n",
    "### **Improving similarity-based recommendation system by tuning its hyperparameters**<a\n",
    "href=\"#Improving-similarity-based-recommendation-system-by-tuning-its-hyperparameters\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Below, we will be tuning hyperparameters for the `KNNBasic` algorithm.\n",
    "Let's try to understand some of the hyperparameters of the KNNBasic\n",
    "algorithm:\n",
    "\n",
    "-   **k** (int) – The (max) number of neighbors to take into account for\n",
    "    aggregation. Default is 40.\n",
    "-   **min_k** (int) – The minimum number of neighbors to take into\n",
    "    account for aggregation. If there are not enough neighbors, the\n",
    "    prediction is set to the global mean of all ratings. Default is 1.\n",
    "-   **sim_options** (dict) – A dictionary of options for the similarity\n",
    "    measure. And there are four similarity measures available in\n",
    "    surprise -\n",
    "    -   cosine\n",
    "    -   msd (default)\n",
    "    -   Pearson\n",
    "    -   Pearson baseline\n",
    "\n",
    "In \\[108\\]:\n",
    "\n",
    "    # Setting up parameter grid to tune the hyperparameters\n",
    "    param_grid = {\n",
    "        'k': [10, 20, 30, 40],                # Number of neighbors\n",
    "        'min_k': [1, 2, 3],                   # Minimum neighbors required\n",
    "        'sim_options': {\n",
    "            'name': ['cosine', 'pearson'],    # Type of similarity measure\n",
    "            'user_based': [True, False]       # User-based or Item-based filtering\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Performing 3-fold cross-validation to tune the hyperparameters\n",
    "    gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "    # Fitting the data\n",
    "    gs.fit(read_data)\n",
    "\n",
    "    # Best RMSE score\n",
    "    print(gs.best_score['rmse'])\n",
    "\n",
    "    # Combination of parameters that gave the best RMSE score\n",
    "    print(gs.best_params['rmse'])\n",
    "\n",
    "    0.9711783271901752\n",
    "    {'k': 40, 'min_k': 3, 'sim_options': {'name': 'cosine', 'user_based': True}}\n",
    "\n",
    "Once the grid search is **complete**, we can get the **optimal values\n",
    "for each of those hyperparameters**.\n",
    "\n",
    "Now, let's build the **final model by using tuned values of the\n",
    "hyperparameters**, which we received by using **grid search\n",
    "cross-validation**.\n",
    "\n",
    "In \\[115\\]:\n",
    "\n",
    "    sim_options = {\n",
    "        'name': 'cosine',       # Replace with the best similarity measure ('cosine' or 'pearson')\n",
    "        'user_based': True      # Set to True for user-user collaborative filtering\n",
    "    }\n",
    "\n",
    "    # Creating an instance of KNNBasic with optimal hyperparameter values\n",
    "    sim_user_user_optimized = KNNBasic(sim_options=sim_options, k=20, min_k=3, random_state=1, verbose=False)  # Replace with optimal 'k' and 'min_k'\n",
    "\n",
    "    # Training the algorithm on the train set\n",
    "    sim_user_user_optimized.fit(trainset)\n",
    "\n",
    "    # Generate predictions on the test set\n",
    "    sim_user_user_optimized.test(testset)\n",
    "\n",
    "    # Let us compute precision@k and recall@k with k=10\n",
    "    precision, recall, f1 = precision_recall_at_k(sim_user_user_optimized, k=10, threshold=3.5)\n",
    "\n",
    "    RMSE: 0.9556\n",
    "    Precision:  0.855\n",
    "    Recall:  0.885\n",
    "    F_1 score:  0.87\n",
    "\n",
    "    ---------------------------------------------------------------------------\n",
    "    TypeError                                 Traceback (most recent call last)\n",
    "    <ipython-input-115-07dace051ffb> in <cell line: 16>()\n",
    "         14 \n",
    "         15 # Let us compute precision@k and recall@k with k=10\n",
    "    ---> 16 precision, recall, f1 = precision_recall_at_k(sim_user_user_optimized, k=10, threshold=3.5)\n",
    "\n",
    "    TypeError: cannot unpack non-iterable NoneType object\n",
    "\n",
    "Through the use of gridsearchcv, we have greatly improved all of our\n",
    "scores by a signifigant margin\n",
    "\n",
    "### **Steps:**<a href=\"#Steps:\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "-   **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and\n",
    "    `prod_id= \"1400501466\"` using the optimized model**\n",
    "-   **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not\n",
    "    interacted with `prod_id =\"1400501466\"`, by using the optimized\n",
    "    model**\n",
    "-   **Compare the output with the output from the baseline model**\n",
    "\n",
    "In \\[119\\]:\n",
    "\n",
    "    # Use sim_user_user_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId 1400501466\n",
    "    prediction = sim_user_user_optimized.predict(\"A3LDPF5FMB782Z\", '1400501466')\n",
    "    print(prediction)\n",
    "\n",
    "    user: A3LDPF5FMB782Z item: 1400501466 r_ui = None   est = 3.40   {'actual_k': 5, 'was_impossible': False}\n",
    "\n",
    "In \\[118\\]:\n",
    "\n",
    "    # Use sim_user_user_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "    prediction2 = sim_user_user_optimized.predict(\"A34BZM6S9L7QI4\", '1400501466')\n",
    "    print(prediction2)\n",
    "\n",
    "    user: A34BZM6S9L7QI4 item: 1400501466 r_ui = None   est = 4.29   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
    "\n",
    "The model beleives that user \"A3LDPF5FMB782Z\" is a better fit for\n",
    "product 1400501466.\n",
    "\n",
    "### **Identifying similar users to a given user (nearest neighbors)**<a href=\"#Identifying-similar-users-to-a-given-user-(nearest-neighbors)\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "We can also find out **similar users to a given user** or its **nearest\n",
    "neighbors** based on this KNNBasic algorithm. Below, we are finding the\n",
    "5 most similar users to the first user in the list with internal id 0,\n",
    "based on the `msd` distance metric.\n",
    "\n",
    "In \\[120\\]:\n",
    "\n",
    "    # 0 is the inner id of the above user\n",
    "    user_inner_id = 0\n",
    "\n",
    "    # Find the 5 most similar users using the similarity matrix (msd distance metric)\n",
    "    similar_users = sim_user_user_optimized.get_neighbors(user_inner_id, k=5)\n",
    "\n",
    "    # Convert internal ids back to raw user ids\n",
    "    similar_user_ids = [trainset.to_raw_uid(inner_id) for inner_id in similar_users]\n",
    "\n",
    "    # Print the most similar users to the first user\n",
    "    print(f\"5 most similar users to user with internal id {user_inner_id}: {similar_user_ids}\")\n",
    "\n",
    "    5 most similar users to user with internal id 0: ['A16J281SJ9QXIQ', 'A1HBI9BBQIG1NH', 'A3VBZDYGHF4NK8', 'AZAC8O310IK4E', 'AM9APPMIE1BHZ']\n",
    "\n",
    "### **Implementing the recommendation algorithm based on optimized KNNBasic model**<a\n",
    "href=\"#Implementing-the-recommendation-algorithm-based-on-optimized-KNNBasic-model\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Below we will be implementing a function where the input parameters are:\n",
    "\n",
    "-   data: A **rating** dataset\n",
    "-   user_id: A user id **against which we want the recommendations**\n",
    "-   top_n: The **number of products we want to recommend**\n",
    "-   algo: the algorithm we want to use **for predicting the ratings**\n",
    "-   The output of the function is a **set of top_n items** recommended\n",
    "    for the given user_id based on the given algorithm\n",
    "\n",
    "In \\[121\\]:\n",
    "\n",
    "    def get_recommendations(data, user_id, top_n, algo):\n",
    "\n",
    "        # Creating an empty list to store the recommended product ids\n",
    "        recommendations = []\n",
    "\n",
    "        # Creating an user item interactions matrix\n",
    "        user_item_interactions_matrix = data.pivot(index = 'user_id', columns = 'prod_id', values = 'rating')\n",
    "\n",
    "        # Extracting those product ids which the user_id has not interacted yet\n",
    "        non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
    "\n",
    "        # Looping through each of the product ids which user_id has not interacted yet\n",
    "        for item_id in non_interacted_products:\n",
    "\n",
    "            # Predicting the ratings for those non interacted product ids by this user\n",
    "            est = algo.predict(user_id, item_id).est\n",
    "\n",
    "            # Appending the predicted ratings\n",
    "            recommendations.append((item_id, est))\n",
    "\n",
    "        # Sorting the predicted ratings in descending order\n",
    "        recommendations.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "        return recommendations[:top_n] # Returing top n highest predicted rating products for this user\n",
    "\n",
    "**Predicting top 5 products for userId = \"A3LDPF5FMB782Z\" with\n",
    "similarity based recommendation system**\n",
    "\n",
    "In \\[123\\]:\n",
    "\n",
    "    # Making top 5 recommendations for user_id \"A3LDPF5FMB782Z\" with a similarity-based recommendation engine\n",
    "    top_5_recommendations = get_recommendations(df_final, \"A3LDPF5FMB782Z\", 5, sim_user_user_optimized)\n",
    "    print(top_5_recommendations)\n",
    "\n",
    "    [('B00005LENO', 5), ('B000067RT6', 5), ('B00006HSML', 5), ('B00006I53X', 5), ('B00006I5J7', 5)]\n",
    "\n",
    "In \\[127\\]:\n",
    "\n",
    "    # Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
    "    top_5_recommendations_df = pd.DataFrame(top_5_recommendations, columns=['prod_id', 'predicted_ratings'])\n",
    "    print(top_5_recommendations_df)\n",
    "\n",
    "          prod_id  predicted_ratings\n",
    "    0  B00005LENO                  5\n",
    "    1  B000067RT6                  5\n",
    "    2  B00006HSML                  5\n",
    "    3  B00006I53X                  5\n",
    "    4  B00006I5J7                  5\n",
    "\n",
    "### **Item-Item Similarity-based Collaborative Filtering Recommendation System**<a\n",
    "href=\"#Item-Item-Similarity-based-Collaborative-Filtering-Recommendation-System\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "-   Above we have seen **similarity-based collaborative filtering**\n",
    "    where similarity is calculated **between users**. Now let us look\n",
    "    into similarity-based collaborative filtering where similarity is\n",
    "    seen **between items**.\n",
    "\n",
    "In \\[130\\]:\n",
    "\n",
    "    # Declaring the similarity options\n",
    "    sim_options = {\n",
    "        'name': 'cosine',\n",
    "        'user_based': False\n",
    "    }\n",
    "\n",
    "    # KNN algorithm is used to find desired similar items. Use random_state=1\n",
    "    sim_based_collab = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
    "\n",
    "    # Train the algorithm on the trainset\n",
    "    sim_based_collab.fit(trainset)\n",
    "\n",
    "    # Predict ratings for the test set using the test() method\n",
    "    sim_based_collab.test(testset)\n",
    "\n",
    "    # Compute precision@k, recall@k, and f1 score with k = 10\n",
    "    precision, recall, f1 = precision_recall_at_k(sim_based_collab, k=10, threshold=3.5)\n",
    "\n",
    "    RMSE: 0.9950\n",
    "    Precision:  0.838\n",
    "    Recall:  0.845\n",
    "    F_1 score:  0.841\n",
    "\n",
    "    ---------------------------------------------------------------------------\n",
    "    TypeError                                 Traceback (most recent call last)\n",
    "    <ipython-input-130-24b5ef58af1c> in <cell line: 17>()\n",
    "         15 \n",
    "         16 # Compute precision@k, recall@k, and f1 score with k = 10\n",
    "    ---> 17 precision, recall, f1 = precision_recall_at_k(sim_based_collab, k=10, threshold=3.5)\n",
    "\n",
    "    TypeError: cannot unpack non-iterable NoneType object\n",
    "\n",
    "Our scores are slightly below right after we did gridsearchcv, but still\n",
    "higher than our initial prediction.\n",
    "\n",
    "Let's now **predict a rating for a user with `userId = A3LDPF5FMB782Z`\n",
    "and `prod_Id = 1400501466`** as shown below. Here the user has already\n",
    "interacted or watched the product with productId \"1400501466\".\n",
    "\n",
    "In \\[132\\]:\n",
    "\n",
    "    # Predicting rating for a sample user with an interacted product\n",
    "    prediction3 = sim_based_collab.predict('A3LDPF5FMB782Z', '1400501466')\n",
    "    print(prediction3)\n",
    "\n",
    "    user: A3LDPF5FMB782Z item: 1400501466 r_ui = None   est = 4.27   {'actual_k': 22, 'was_impossible': False}\n",
    "\n",
    "Our model belives that used A3LDPF5FMB782Z is a good fit for the product\n",
    "1400501466\n",
    "\n",
    "Below we are **predicting rating for the `userId = A34BZM6S9L7QI4` and\n",
    "`prod_id = 1400501466`**.\n",
    "\n",
    "In \\[133\\]:\n",
    "\n",
    "    # Predicting rating for a sample user with a non interacted product\n",
    "    prediction4 = sim_based_collab.predict('A34BZM6S9L7QI4', '1400501466')\n",
    "    print(prediction4)\n",
    "\n",
    "    user: A34BZM6S9L7QI4 item: 1400501466 r_ui = None   est = 4.29   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
    "\n",
    "Our model belives that User A34BZM6S9L7QI4 is not a good fit for the\n",
    "product, unlike the previous user\n",
    "\n",
    "### **Hyperparameter tuning the item-item similarity-based model**<a href=\"#Hyperparameter-tuning-the-item-item-similarity-based-model\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "-   Use the following values for the param_grid and tune the model.\n",
    "    -   'k': \\[10, 20, 30\\]\n",
    "    -   'min_k': \\[3, 6, 9\\]\n",
    "    -   'sim_options': {'name': \\['msd', 'cosine'\\]\n",
    "    -   'user_based': \\[False\\]\n",
    "-   Use GridSearchCV() to tune the model using the 'rmse' measure\n",
    "-   Print the best score and best parameters\n",
    "\n",
    "In \\[135\\]:\n",
    "\n",
    "    # Setting up parameter grid to tune the hyperparameters\n",
    "    param_grid = {\n",
    "        'k': [10, 20, 30],\n",
    "        'min_k': [3, 6, 9],\n",
    "        'sim_options': {\n",
    "            'name': ['msd', 'cosine'],\n",
    "            'user_based': [False]\n",
    "        }\n",
    "    }\n",
    "    # Performing 3-fold cross validation to tune the hyperparameters\n",
    "    gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "    # Fitting the data\n",
    "    gs.fit(read_data)\n",
    "    # Find the best RMSE score\n",
    "    print(f\"Best RMSE score: {gs.best_score['rmse']}\")\n",
    "\n",
    "    # Find the combination of parameters that gave the best RMSE score\n",
    "    print(f\"Best parameters: {gs.best_params['rmse']}\")\n",
    "\n",
    "    Best RMSE score: 0.9747148198726343\n",
    "    Best parameters: {'k': 30, 'min_k': 6, 'sim_options': {'name': 'msd', 'user_based': False}}\n",
    "\n",
    "Once the **grid search** is complete, we can get the **optimal values\n",
    "for each of those hyperparameters as shown above.**\n",
    "\n",
    "Now let's build the **final model** by using **tuned values of the\n",
    "hyperparameters** which we received by using grid search\n",
    "cross-validation.\n",
    "\n",
    "### **Use the best parameters from GridSearchCV to build the optimized item-item similarity-based model. Compare the performance of the optimized model with the baseline model.**<a\n",
    "href=\"#Use-the-best-parameters-from-GridSearchCV-to-build-the-optimized-item-item-similarity-based-model.-Compare-the-performance-of-the-optimized-model-with-the-baseline-model.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[137\\]:\n",
    "\n",
    "    # Using the optimal similarity measure for item-item based collaborative filtering\n",
    "    sim_options = {\n",
    "        'name': 'msd',\n",
    "        'user_based': False\n",
    "    }\n",
    "    # Creating an instance of KNNBasic with optimal hyperparameter values\n",
    "    optimal_knn = KNNBasic(k=30, min_k=6, sim_options=sim_options, random_state=1)\n",
    "\n",
    "    # Training the algorithm on the trainset\n",
    "    optimal_knn.fit(trainset)\n",
    "    optimal_knn.test(testset)\n",
    "\n",
    "    # Let us compute precision@k and recall@k, f1_score and RMSE\n",
    "    precision, recall, f1 = precision_recall_at_k(optimal_knn, k=10, threshold=3.5)\n",
    "\n",
    "    Computing the msd similarity matrix...\n",
    "    Done computing similarity matrix.\n",
    "    RMSE: 0.9576\n",
    "    Precision:  0.839\n",
    "    Recall:  0.88\n",
    "    F_1 score:  0.859\n",
    "\n",
    "    ---------------------------------------------------------------------------\n",
    "    TypeError                                 Traceback (most recent call last)\n",
    "    <ipython-input-137-c04649cc64c5> in <cell line: 14>()\n",
    "         12 \n",
    "         13 # Let us compute precision@k and recall@k, f1_score and RMSE\n",
    "    ---> 14 precision, recall, f1 = precision_recall_at_k(optimal_knn, k=10, threshold=3.5)\n",
    "\n",
    "    TypeError: cannot unpack non-iterable NoneType object\n",
    "\n",
    "Similar to before, our scores are good but worse than after our inital\n",
    "gridsearch. The results are still satisfactory\n",
    "\n",
    "### **Steps:**<a href=\"#Steps:\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "-   **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and\n",
    "    `prod_id= \"1400501466\"` using the optimized model**\n",
    "-   **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not\n",
    "    interacted with `prod_id =\"1400501466\"`, by using the optimized\n",
    "    model**\n",
    "-   **Compare the output with the output from the baseline model**\n",
    "\n",
    "In \\[138\\]:\n",
    "\n",
    "    # Use sim_item_item_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
    "    optimized_prediction_1 = optimal_knn.predict('A3LDPF5FMB782Z', '1400501466')\n",
    "    print(optimized_prediction_1)\n",
    "\n",
    "    user: A3LDPF5FMB782Z item: 1400501466 r_ui = None   est = 4.67   {'actual_k': 22, 'was_impossible': False}\n",
    "\n",
    "In \\[140\\]:\n",
    "\n",
    "    # Use sim_item_item_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "    optimized_prediction_2 = optimal_knn.predict('A34BZM6S9L7QI4', '1400501466')\n",
    "    print(optimized_prediction_2)\n",
    "\n",
    "    user: A34BZM6S9L7QI4 item: 1400501466 r_ui = None   est = 4.29   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
    "\n",
    "Our model tells us that the user who interacted with the product is a\n",
    "better fit than the user who has not interacted with the product.\n",
    "\n",
    "### **Identifying similar items to a given item (nearest neighbors)**<a href=\"#Identifying-similar-items-to-a-given-item-(nearest-neighbors)\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "We can also find out **similar items** to a given item or its nearest\n",
    "neighbors based on this **KNNBasic algorithm**. Below we are finding the\n",
    "5 most similar items to the item with internal id 0 based on the `msd`\n",
    "distance metric.\n",
    "\n",
    "In \\[142\\]:\n",
    "\n",
    "    similar_items = optimal_knn.get_neighbors(0, k=5)\n",
    "    similar_item_ids = [trainset.to_raw_iid(inner_id) for inner_id in similar_items]\n",
    "    print(similar_item_ids)\n",
    "\n",
    "    ['B008X9Z3UC', 'B003ZSHKJ8', 'B003LSTD38', 'B005EOWBKE', 'B004IZN3WU']\n",
    "\n",
    "**Predicting top 5 products for userId = \"A1A5KUIIIHFF4U\" with\n",
    "similarity based recommendation system.**\n",
    "\n",
    "**Hint:** Use the get_recommendations() function.\n",
    "\n",
    "In \\[144\\]:\n",
    "\n",
    "    # Making top 5 recommendations for user_id A1A5KUIIIHFF4U with similarity-based recommendation engine.\n",
    "    top_5 = get_recommendations(df_final, \"A1A5KUIIIHFF4U\", 5, optimal_knn)\n",
    "    print(top_5)\n",
    "\n",
    "    [('1400532655', 4.292024046561495), ('1400599997', 4.292024046561495), ('9983891212', 4.292024046561495), ('B00000DM9W', 4.292024046561495), ('B00000J1V5', 4.292024046561495)]\n",
    "\n",
    "In \\[146\\]:\n",
    "\n",
    "    # Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
    "    top_5_df = pd.DataFrame(top_5, columns = ['prod_id', 'predicted_ratings'])\n",
    "    print(top_5_df)\n",
    "\n",
    "          prod_id  predicted_ratings\n",
    "    0  1400532655           4.292024\n",
    "    1  1400599997           4.292024\n",
    "    2  9983891212           4.292024\n",
    "    3  B00000DM9W           4.292024\n",
    "    4  B00000J1V5           4.292024\n",
    "\n",
    "Now as we have seen **similarity-based collaborative filtering\n",
    "algorithms**, let us now get into **model-based collaborative filtering\n",
    "algorithms**.\n",
    "\n",
    "### **Model 3: Model-Based Collaborative Filtering - Matrix Factorization**<a\n",
    "href=\"#Model-3:-Model-Based-Collaborative-Filtering---Matrix-Factorization\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Model-based Collaborative Filtering is a **personalized recommendation\n",
    "system**, the recommendations are based on the past behavior of the user\n",
    "and it is not dependent on any additional information. We use **latent\n",
    "features** to find recommendations for each user.\n",
    "\n",
    "### Singular Value Decomposition (SVD)<a href=\"#Singular-Value-Decomposition-(SVD)\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "SVD is used to **compute the latent features** from the **user-item\n",
    "matrix**. But SVD does not work when we **miss values** in the\n",
    "**user-item matrix**.\n",
    "\n",
    "In \\[149\\]:\n",
    "\n",
    "    # Using SVD matrix factorization. Use random_state = 1\n",
    "    svd = SVD(random_state=1)\n",
    "\n",
    "    # Training the algorithm on the trainset\n",
    "    svd.fit(trainset)\n",
    "    svd.test(testset)\n",
    "\n",
    "    # Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "    precision, recall, f1 = precision_recall_at_k(svd, k=10, threshold=3.5)\n",
    "\n",
    "    RMSE: 0.8882\n",
    "    Precision:  0.853\n",
    "    Recall:  0.88\n",
    "    F_1 score:  0.866\n",
    "\n",
    "    ---------------------------------------------------------------------------\n",
    "    TypeError                                 Traceback (most recent call last)\n",
    "    <ipython-input-149-ecf9272a5ded> in <cell line: 9>()\n",
    "          7 \n",
    "          8 # Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "    ----> 9 precision, recall, f1 = precision_recall_at_k(svd, k=10, threshold=3.5)\n",
    "\n",
    "    TypeError: cannot unpack non-iterable NoneType object\n",
    "\n",
    "svd provides descent scores across the board, but can be better\n",
    "optimized\n",
    "\n",
    "**Let's now predict the rating for a user with\n",
    "`userId = \"A3LDPF5FMB782Z\"` and `prod_id = \"1400501466`.**\n",
    "\n",
    "In \\[150\\]:\n",
    "\n",
    "    # Making prediction\n",
    "    svd.predict(\"A3LDPF5FMB782Z\", \"1400501466\", r_ui = 5, verbose = True)\n",
    "\n",
    "    user: A3LDPF5FMB782Z item: 1400501466 r_ui = 5.00   est = 4.08   {'was_impossible': False}\n",
    "\n",
    "Out\\[150\\]:\n",
    "\n",
    "    Prediction(uid='A3LDPF5FMB782Z', iid='1400501466', r_ui=5, est=4.081406749810685, details={'was_impossible': False})\n",
    "\n",
    "svd model believes that this candidate is a good fit for this product\n",
    "\n",
    "**Below we are predicting rating for the `userId = \"A34BZM6S9L7QI4\"` and\n",
    "`productId = \"1400501466\"`.**\n",
    "\n",
    "In \\[151\\]:\n",
    "\n",
    "    # Making prediction\n",
    "    svd.predict(\"A34BZM6S9L7QI4\", \"1400501466\", verbose = True)\n",
    "\n",
    "    user: A34BZM6S9L7QI4 item: 1400501466 r_ui = None   est = 4.40   {'was_impossible': False}\n",
    "\n",
    "Out\\[151\\]:\n",
    "\n",
    "    Prediction(uid='A34BZM6S9L7QI4', iid='1400501466', r_ui=None, est=4.40037568046934, details={'was_impossible': False})\n",
    "\n",
    "The svd model also believes that this user is a good fit for this\n",
    "product\n",
    "\n",
    "### **Improving Matrix Factorization based recommendation system by tuning its hyperparameters**<a\n",
    "href=\"#Improving-Matrix-Factorization-based-recommendation-system-by-tuning-its-hyperparameters\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Below we will be tuning only three hyperparameters:\n",
    "\n",
    "-   **n_epochs**: The number of iterations of the SGD algorithm.\n",
    "-   **lr_all**: The learning rate for all parameters.\n",
    "-   **reg_all**: The regularization term for all parameters.\n",
    "\n",
    "In \\[153\\]:\n",
    "\n",
    "    # Set the parameter space to tune\n",
    "    param_grid = {\n",
    "        'n_epochs': [10, 20, 30],\n",
    "        'lr_all': [0.001, 0.005, 0.01],\n",
    "        'reg_all': [0.2, 0.4, 0.6]\n",
    "    }\n",
    "\n",
    "    # Performing 3-fold gridsearch cross-validation\n",
    "    gs_ = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "    # Fitting the data (replace 'data' with your dataset)\n",
    "    gs_.fit(read_data)\n",
    "\n",
    "    # Best RMSE score\n",
    "    print(f\"Best RMSE score: {gs_.best_score['rmse']}\")\n",
    "\n",
    "    # Combination of parameters that gave the best RMSE score\n",
    "    print(f\"Best parameters: {gs_.best_params['rmse']}\")\n",
    "\n",
    "    Best RMSE score: 0.8972447349355157\n",
    "    Best parameters: {'n_epochs': 20, 'lr_all': 0.01, 'reg_all': 0.2}\n",
    "\n",
    "Now, we will **the build final model** by using **tuned values** of the\n",
    "hyperparameters, which we received using grid search cross-validation\n",
    "above.\n",
    "\n",
    "In \\[155\\]:\n",
    "\n",
    "    # Build the optimized SVD model using optimal hyperparameter search. Use random_state=1\n",
    "    svd_optimized = SVD(n_epochs=20, lr_all=0.01, reg_all=0.2, random_state=1)\n",
    "\n",
    "    # Train the algorithm on the trainset\n",
    "    svd_optimized.fit(trainset)\n",
    "    svd_optimized.test(testset)\n",
    "\n",
    "    # Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "    precision, recall, f1 = precision_recall_at_k(svd_optimized, k=10, threshold=3.5)\n",
    "\n",
    "    RMSE: 0.8808\n",
    "    Precision:  0.854\n",
    "    Recall:  0.878\n",
    "    F_1 score:  0.866\n",
    "\n",
    "    ---------------------------------------------------------------------------\n",
    "    TypeError                                 Traceback (most recent call last)\n",
    "    <ipython-input-155-aa06c8679936> in <cell line: 9>()\n",
    "          7 \n",
    "          8 # Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "    ----> 9 precision, recall, f1 = precision_recall_at_k(svd_optimized, k=10, threshold=3.5)\n",
    "\n",
    "    TypeError: cannot unpack non-iterable NoneType object\n",
    "\n",
    "The optimization of our svd gives marginally better scores. While it is\n",
    "not signifigant, it is still worth doing\n",
    "\n",
    "### **Steps:**<a href=\"#Steps:\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "-   **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and\n",
    "    `prod_id= \"1400501466\"` using the optimized model**\n",
    "-   **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not\n",
    "    interacted with `prod_id =\"1400501466\"`, by using the optimized\n",
    "    model**\n",
    "-   **Compare the output with the output from the baseline model**\n",
    "\n",
    "In \\[157\\]:\n",
    "\n",
    "    # Use svd_algo_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
    "    svd_pred = svd_optimized.predict(\"A3LDPF5FMB782Z\", \"1400501466\")\n",
    "    print(svd_pred)\n",
    "\n",
    "    user: A3LDPF5FMB782Z item: 1400501466 r_ui = None   est = 4.13   {'was_impossible': False}\n",
    "\n",
    "In \\[158\\]:\n",
    "\n",
    "    # Use svd_algo_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "    svd_pred2 = svd_optimized.predict(\"A34BZM6S9L7QI4\", \"1400501466\")\n",
    "    print(svd_pred2)\n",
    "\n",
    "    user: A34BZM6S9L7QI4 item: 1400501466 r_ui = None   est = 4.22   {'was_impossible': False}\n",
    "\n",
    "### **Conclusion and Recommendations**<a href=\"#Conclusion-and-Recommendations\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "The final optimized SVD model showed a strong performance, with an RMSE\n",
    "score of 0.897, which is quite good for a recommendation system. This\n",
    "indicates that matrix factorization was effective in predicting missing\n",
    "ratings and providing personalized recommendations.\n",
    "\n",
    "Item-based collaborative filtering models also performed well,\n",
    "particularly for users who have interacted with similar products. This\n",
    "is effective for recommending products that are similar to those already\n",
    "liked or purchased by users.\n",
    "\n",
    "Tuning the model hyperparameters (e.g., number of epochs, learning rate,\n",
    "and regularization) improved performance significantly. For example,\n",
    "finding optimal values such as n_epochs=20, lr_all=0.01, and reg_all=0.2\n",
    "improved the RMSE score.\n",
    "\n",
    "One potential issue is the cold-start problem, where the system may\n",
    "struggle to provide accurate recommendations for new users or items that\n",
    "have very few interactions in the dataset.\n",
    "\n",
    "Recomendations:\n",
    "\n",
    "SVD and matrix factorization techniques work well for personalized\n",
    "recommendations. The company should invest in tuning and deploying these\n",
    "models at scale, as they perform well in predicting ratings and handling\n",
    "sparse user-item interactions.\n",
    "\n",
    "While collaborative filtering is effective, integrating content-based\n",
    "filtering could help address the cold-start problem for new users and\n",
    "products. By analyzing product features (e.g., category, brand) or user\n",
    "demographics, the system can make better recommendations even when\n",
    "user-item interaction data is sparse.\n",
    "\n",
    "Hyperparameter tuning significantly improved model performance in this\n",
    "project. The company should continue to experiment with larger parameter\n",
    "spaces and potentially more advanced optimization techniques like\n",
    "Bayesian Optimization to further improve performance.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    #@title Convert ipynb to HTML in Colab\n",
    "    # Upload ipynb\n",
    "    from google.colab import files\n",
    "    f = files.upload()\n",
    "\n",
    "    # Convert ipynb to html\n",
    "    import subprocess\n",
    "    file0 = list(f.keys())[0]\n",
    "    _ = subprocess.run([\"pip\", \"install\", \"nbconvert\"])\n",
    "    _ = subprocess.run([\"jupyter\", \"nbconvert\", file0, \"--to\", \"html\"])\n",
    "\n",
    "    # download the html\n",
    "    files.download(file0[:-5]+\"html\")\n",
    "\n",
    "Upload widget is only available when the cell has been executed in the\n",
    "current browser session. Please rerun this cell to enable.\n",
    "\n",
    "In \\[ \\]:"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
